services:
  ollama:
    build: ./ollama
    container_name: ollama
    ports:
      - "11500:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped



  web_search_agent:
    build:
      context: ./agents/web_search_agent
      dockerfile: Dockerfile
    container_name: web_search_agent
    environment:
      - OLLAMA_ENDPOINT=http://ollama:11434
      - MODEL_NAME=llama3.2:3b            # 建議加上
      - TAVILY_API_KEY=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
      - USE_MOCK=true
    ports:
      - "8001:8001"
    depends_on:
      - ollama
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:3000"
    depends_on:
      - web_search_agent
    restart: unless-stopped

volumes:
  ollama_data:
